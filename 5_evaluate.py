# -*- coding: utf-8 -*-
"""5. evaluate

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KeUkwEAB5RDp0iZnr4TXQ4GQ0TF_Qqcv
"""

import numpy as np
import matplotlib.pyplot as plt
import torchvision.utils
import torch
from torchvision.datasets import MNIST
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from model import VariationalAutoencoder
from train import vae_loss, latent_dims

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
batch_size = 128

vae = VariationalAutoencoder()
vae.load_state_dict(torch.load('vae_model.pth'))
vae = vae.to(device)

img_transform = transforms.Compose([
    transforms.ToTensor()
])
test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

# set to evaluation mode
vae.eval()

test_loss_avg, num_batches = 0, 0
for image_batch, _ in test_dataloader:

    with torch.no_grad():

        image_batch = image_batch.to(device)

        # vae reconstruction
        image_batch_recon, latent_mu, latent_logvar = vae(image_batch)

        # reconstruction error
        loss = vae_loss(image_batch_recon, image_batch, latent_mu, latent_logvar)

        test_loss_avg += loss.item()
        num_batches += 1

test_loss_avg /= num_batches
print('average reconstruction error: %f' % (test_loss_avg))

"""**Pracice 2 (Spherical Linear Interpolation).** In the previous interpolation function, the latent vectors were combined by simple linear interpolation:
\begin{equation} z_{\lambda}^{\mathrm{lin}} = (1-\lambda) z_1 + \lambda z_2,\qquad 0 \leq \lambda \leq 1.
\end{equation}

However, since the latent prior distribution of a Variational Autoencoder is the isotropic Gaussian $\mathcal{N}(0,I)$, a more natural interpolation scheme is the *spherical linear interpolation (Slerp)* defined as

\begin{equation}
z_{\lambda}^{\mathrm{slerp}}
= \frac{\sin\!\big((1-\lambda)\theta\big)}{\sin\theta}\,z_1
+ \frac{\sin\!\big(\lambda\theta\big)}{\sin\theta}\,z_2,
\quad
\theta = \cos^{-1}\!\left(\frac{z_1 \cdot z_2}{\|z_1\|\,\|z_2\|}\right).
\end{equation}

* Implement the spherical linear interpolation function $\textrm{slerp}(z_1, z_2, \lambda)$ in PyTorch.
* Compare the reconstructed digits obtained from linear interpolation and spherical interpolation for the same pair of images.
* Discuss which interpolation better preserves the geometry of the Gaussian latent space and why.


"""

plt.ion()

def to_img(x):
    x = x.clamp(0, 1)
    return x

def show_image(img):
    img = to_img(img)
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))

def visualise_output(images, model):

    with torch.no_grad():

        images = images.to(device)
        images, _, _ = model(images)
        images = images.cpu()
        images = to_img(images)
        np_imagegrid = torchvision.utils.make_grid(images[1:50], 10, 5).numpy()
        plt.imshow(np.transpose(np_imagegrid, (1, 2, 0)))
        plt.show()

vae.eval()


def interpolation(lambda1, model, img1, img2):

    with torch.no_grad():

        # latent vector of first image
        img1 = img1.to(device)
        latent_1, _ = model.encoder(img1)

        # latent vector of second image
        img2 = img2.to(device)
        latent_2, _ = model.encoder(img2)

        # Linear interpolation
        #inter_latent = lambda1* latent_1 + (1- lambda1) * latent_2 ######### LAMBDA 가 1보다 크게 되면 외분점이 나와서 이상한 결과가 나온다

        # Slerp
        dot = torch.sum(latent_1 * latent_2, dim=1, keepdim=True)
        norm_1 = torch.norm(latent_1, dim=1, keepdim=True)
        norm_2 = torch.norm(latent_2, dim=1, keepdim=True)
        theta = torch.acos(torch.clamp(dot / (norm_1 * norm_2), -1.0, 1.0))
        sin_theta = torch.sin(theta)
        w1 = torch.sin((1 - lambda1) * theta) / sin_theta
        w2 = torch.sin(lambda1 * theta) / sin_theta
        inter_latent = w1 * latent_1 + w2 * latent_2


        # reconstruct interpolated image
        inter_image = model.decoder(inter_latent)
        inter_image = inter_image.cpu()

        return inter_image

# sort part of test set by digit
digits = [[] for _ in range(10)]
for img_batch, label_batch in test_dataloader:
    for i in range(img_batch.size(0)):
        digits[label_batch[i]].append(img_batch[i:i+1])
    if sum(len(d) for d in digits) >= 1000:
        break;

# interpolation lambdas
lambda_range=np.linspace(0,1,10)

fig, axs = plt.subplots(2,5, figsize=(15, 6))
fig.subplots_adjust(hspace = .5, wspace=.001)
axs = axs.ravel()

for ind,l in enumerate(lambda_range):
    inter_image=interpolation(float(l), vae, digits[7][0], digits[1][0]) #####INTERPOLATE BETWEEN 7 AND 1

    inter_image = to_img(inter_image)

    image = inter_image.numpy()

    axs[ind].imshow(image[0,0,:,:], cmap='gray')
    axs[ind].set_title('lambda_val='+str(round(l,1)))
plt.show()

vae.eval()

with torch.no_grad():

    # sample latent vectors from the normal distribution
    latent = torch.randn(128, latent_dims, device=device)

    # reconstruct images from the latent vectors
    img_recon = vae.decoder(latent)
    img_recon = img_recon.cpu()

    fig, ax = plt.subplots(figsize=(5, 5))
    show_image(torchvision.utils.make_grid(img_recon.data[:100],10,5))
    plt.show()

# load a network that was trained with a 2d latent space
if latent_dims != 2:
    print('Please change the parameters to two latent dimensions.')

with torch.no_grad():

    # create a sample grid in 2d latent space
    latent_x = np.linspace(-1.5,1.5,20)
    latent_y = np.linspace(-1.5,1.5,20)
    latents = torch.FloatTensor(len(latent_y), len(latent_x), 2)
    for i, lx in enumerate(latent_x):
        for j, ly in enumerate(latent_y):
            latents[j, i, 0] = lx
            latents[j, i, 1] = ly
    latents = latents.view(-1, 2) # flatten grid into a batch

    # reconstruct images from the latent vectors
    latents = latents.to(device)
    image_recon = vae.decoder(latents)
    image_recon = image_recon.cpu()

    fig, ax = plt.subplots(figsize=(10, 10))
    show_image(torchvision.utils.make_grid(image_recon.data[:400],20,5))
    plt.show()